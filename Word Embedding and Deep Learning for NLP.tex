	\chapter{Word Embedding and Deep Learning for NLP}

For more information:
	\begin{bulletedlist}
		\item \textbf{Model saving and production}: Sentiment Analysis mentored learning session (July 30, 2022) at time 1:36.
	\end{bulletedlist}

	\section{Drift Monitor}
A drift monitor is a simple machine learning model that can distinguish between the distribution of the training data and production data.  As soon as the area under curve of that model reaches 60 or 70 percent it means the training and production model distribution is different and retraining is needed.

	\section{NLP using Deep Learning}

	\begin{bulletedlist}
		\item Recently, deep learning methods have obtained very high performance across many different NLP tasks.
		\item The ability of deep learning in the field of NLP is the better achievements by models that may require more data but less linguistic expertise to train and operate.
		\item Some of the few large demonstrations of the potential of deep learning were in natural language processing, specifically speech recognition and recently in machine translation.
	\end{bulletedlist}

	\subsection{Potential of Deep Learning for NLP}

	\begin{bulletedlist}
		\item \textbf{New NLP Model} Deep Learning technique offers the opportunity of new modeling approaches to challenging natural language problems like sequence-to-sequence prediction.
		\item \textbf{Drop-in Substitution Models} Deep learning technique can be dropped into existing natural language systems as replacement models that can achieve equivalent or better performance.
	\end{bulletedlist}

	\subsection{Dense Encoding: Word Embedding} 